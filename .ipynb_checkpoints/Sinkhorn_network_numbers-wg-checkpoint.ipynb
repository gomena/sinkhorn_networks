{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import optimizer\n",
    "import sinkhorn_ops\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define some ad-hoc merging, splitting and mixing functions\n",
    "\n",
    "\n",
    "\n",
    "def soft_to_hard(soft_perm):\n",
    "    \n",
    "    a,b = linear_sum_assignment(-soft_perm)\n",
    "    ma = np.zeros((np.shape(soft_perm)))\n",
    "    for i in range(soft_perm.shape[0]):\n",
    "        ma[i, b[i]] = 1\n",
    "    return ma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model params\n",
    "batch_size = 10\n",
    "n_iter = 2000\n",
    "samples_per_num = 10\n",
    "n_iter_sinkhorn = 20\n",
    "noise_factor = 0.0\n",
    "keep_prob =1.0\n",
    "opt = 'adam'\n",
    "n_units = 32\n",
    "temp = 0.5\n",
    "lr = 0.01\n",
    "\n",
    "#mnist data\n",
    "\n",
    "n_channels = 1\n",
    "\n",
    "n_numbers = 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main neural network definitions\n",
    "\n",
    "def create_log_alpha():\n",
    "    with tf.variable_scope(\"model_params\"):\n",
    "        # each number is processed with the same network, so data is reshaped\n",
    "        # so that numbers occupy the 'batch' position.\n",
    "        random_flattened = tf.reshape(random, [-1, 1])\n",
    "        # net: output of the first neural network that connects numbers to a\n",
    "        # 'latent' representation.\n",
    "        net = fc(random_flattened, n_units)\n",
    "        # now those latent representation is connected to rows of the matrix\n",
    "        # log_alpha.\n",
    "        processed = fc(net, n_numbers, activation_fn=None)\n",
    "\n",
    "        # the matrix log_alpha is created by concatenation of the rows\n",
    "        # corresponding to different numbers.\n",
    "        return  tf.reshape(processed, [-1, n_numbers, n_numbers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gomena/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/gomena/.local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "#Now we define the main TF variables\n",
    "\n",
    "random = tf.placeholder(tf.float32,[None, n_numbers])\n",
    "random_tiled = tf.tile(random, [samples_per_num, 1])\n",
    "\n",
    "\n",
    "ordered = tf.placeholder(tf.float32,[None, n_numbers])\n",
    "ordered_tiled = tf.tile(ordered, [samples_per_num, 1])\n",
    "\n",
    "\n",
    "temperature = tf.constant(temp, dtype=tf.float32)\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "fc = tf.contrib.layers.fully_connected\n",
    "\n",
    "\n",
    "log_alpha = create_log_alpha()\n",
    "(soft_perms_inf, log_alpha_w_noise) = sinkhorn_ops.gumbel_sinkhorn(log_alpha, temp, samples_per_num,\n",
    "                                                                   noise_factor, n_iter_sinkhorn, squeeze=False)\n",
    "\n",
    "inv_soft_perms = tf.transpose(soft_perms_inf, [0, 1, 3, 2])\n",
    "inv_soft_perms_flat = tf.reshape(\n",
    "  tf.transpose(inv_soft_perms, [1, 0, 2, 3]),\n",
    "  [-1, n_numbers, n_numbers])\n",
    "ordered_tiled = tf.reshape(ordered_tiled, [-1, n_numbers, 1])\n",
    "random_tiled = tf.reshape(random_tiled, [-1, n_numbers, 1])\n",
    "# squared l2 loss\n",
    "ordered_inf = tf.matmul(inv_soft_perms_flat, random_tiled)\n",
    "l2s_diff = tf.reduce_mean(\n",
    "  tf.square(\n",
    "      ordered_tiled - ordered_inf))\n",
    "opt = optimizer.set_optimizer(opt, lr, opt_eps=1e-8)\n",
    "train_op = tf.contrib.training.create_train_op(l2s_diff, opt, global_step=global_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gomena/.local/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Step 1, Loss: 0.0840598\n",
      "Step 51, Loss: 0.0055281\n",
      "Step 101, Loss: 0.0028687\n",
      "Step 151, Loss: 0.0021368\n",
      "Step 201, Loss: 0.0016496\n",
      "Step 251, Loss: 0.0013368\n",
      "Step 301, Loss: 0.0011855\n",
      "Step 351, Loss: 0.0011260\n",
      "Step 401, Loss: 0.0009740\n",
      "Step 451, Loss: 0.0008525\n",
      "Step 501, Loss: 0.0008044\n",
      "Step 551, Loss: 0.0007922\n",
      "Step 601, Loss: 0.0007446\n",
      "Step 651, Loss: 0.0007383\n",
      "Step 701, Loss: 0.0006906\n",
      "Step 751, Loss: 0.0006846\n",
      "Step 801, Loss: 0.0006213\n",
      "Step 851, Loss: 0.0006534\n",
      "Step 901, Loss: 0.0006207\n",
      "Step 951, Loss: 0.0005681\n",
      "Step 1001, Loss: 0.0005987\n",
      "Step 1051, Loss: 0.0005739\n",
      "Step 1101, Loss: 0.0005626\n",
      "Step 1151, Loss: 0.0005161\n",
      "Step 1201, Loss: 0.0005559\n",
      "Step 1251, Loss: 0.0004950\n",
      "Step 1301, Loss: 0.0005211\n",
      "Step 1351, Loss: 0.0004604\n",
      "Step 1401, Loss: 0.0004533\n",
      "Step 1451, Loss: 0.0004530\n",
      "Step 1501, Loss: 0.0004497\n",
      "Step 1551, Loss: 0.0004997\n",
      "Step 1601, Loss: 0.0004565\n",
      "Step 1651, Loss: 0.0004260\n",
      "Step 1701, Loss: 0.0004474\n",
      "Step 1751, Loss: 0.0003755\n",
      "Step 1801, Loss: 0.0004535\n",
      "Step 1851, Loss: 0.0003865\n",
      "Step 1901, Loss: 0.0003903\n",
      "Step 1951, Loss: 0.0004623\n"
     ]
    }
   ],
   "source": [
    "#Lets train the model\n",
    "\n",
    "init_op=tf.initialize_all_variables()\n",
    "sess=tf.InteractiveSession()\n",
    "sess.run(init_op)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    random_np = np.random.uniform(0,1,[batch_size, n_numbers])\n",
    "    ordered_np = np.sort(random_np)\n",
    "    _,loss=sess.run([train_op,l2s_diff],{random:random_np,\n",
    "                                             ordered:ordered_np})\n",
    "    \n",
    "   \n",
    "    if i % 50 == 1:\n",
    "        print('Step %d, Loss: %0.7f' % (i,loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_np = np.random.uniform(0,1,[batch_size, n_numbers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04298256 0.05516958 0.06514744 0.07619594 0.08884865 0.10382549\n",
      " 0.12259267 0.14200354 0.16023368 0.18461217 0.2042279  0.2215375\n",
      " 0.2384247  0.2505739  0.2700228  0.2878091  0.31348217 0.33356926\n",
      " 0.35415912 0.37486604 0.40236765 0.4368863  0.46433488 0.49136335\n",
      " 0.5053771  0.5265703  0.5426044  0.5642296  0.5777352  0.5988354\n",
      " 0.6142919  0.6366211  0.654852   0.6754171  0.6986308  0.716693\n",
      " 0.7306363  0.7468735  0.7636677  0.7780587  0.79345375 0.8126777\n",
      " 0.83494306 0.8586026  0.878752   0.89743906 0.91362494 0.92575806\n",
      " 0.9370681  0.94443756]\n",
      "[0.04298256 0.05516958 0.06514744 0.07619594 0.08884865 0.10382549\n",
      " 0.12259267 0.14200354 0.16023368 0.18461217 0.2042279  0.2215375\n",
      " 0.2384247  0.2505739  0.2700228  0.2878091  0.31348217 0.33356926\n",
      " 0.35415912 0.37486604 0.40236765 0.4368863  0.46433488 0.49136335\n",
      " 0.5053771  0.5265703  0.5426044  0.5642296  0.5777352  0.5988354\n",
      " 0.6142919  0.6366211  0.654852   0.6754171  0.6986308  0.716693\n",
      " 0.7306363  0.7468735  0.7636677  0.7780587  0.79345375 0.8126777\n",
      " 0.83494306 0.8586026  0.878752   0.89743906 0.91362494 0.92575806\n",
      " 0.9370681  0.94443756]\n"
     ]
    }
   ],
   "source": [
    "ordered_np = np.sort(random_np)\n",
    "orde=sess.run(ordered_inf,{random:random_np,ordered:ordered_np})\n",
    "orde2=sess.run(ordered_inf,{random:random_np,ordered:random_np})\n",
    "      \n",
    "print(orde[0,:,0])\n",
    "print(orde2[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(orde.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joined_scrambled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2353eb89337d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoined_scrambled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'joined_scrambled' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(joined_scrambled[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.matmul(s, np.transpose(s, [0,2,1]))[0,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
