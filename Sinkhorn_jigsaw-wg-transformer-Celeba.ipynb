{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import optimizer\n",
    "import sinkhorn_ops\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from tensorflow import keras\n",
    "%matplotlib inline\n",
    "import tensorflow_datasets as tfds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "def sinkhorn(log_alpha, n_iters=20):\n",
    "\n",
    "    for _ in range(n_iters):\n",
    "        log_alpha -= logsumexp(log_alpha, axis=1, keepdims=True)\n",
    "        log_alpha -= logsumexp(log_alpha, axis=0, keepdims=True)\n",
    "    log_alpha -= logsumexp(log_alpha, axis=1, keepdims=True)\n",
    "    return np.exp(log_alpha)\n",
    "\n",
    "def batch_split(batch, n_squares_side, n_channels=1):\n",
    "    if(n_channels ==1):\n",
    "        side = int(np.sqrt(batch.shape[1]))\n",
    "    else:\n",
    "        side = batch.shape[1]\n",
    "    batch_size = batch.shape[0]\n",
    "    n_squares = n_squares_side ** 2\n",
    "    \n",
    "    batch = np.reshape(batch, [-1, side, side, n_channels])\n",
    "    batch = np.reshape(batch, [batch_size, n_squares_side, side/n_squares_side, side, n_channels])\n",
    "    batch = np.transpose(batch, [0, 2, 1, 3, 4])\n",
    "    batch = np.reshape(batch, [batch_size, side/n_squares_side, n_squares, side/n_squares_side, n_channels])\n",
    "    batch = np.transpose(batch, [0, 2, 1, 3, 4])\n",
    "    return batch\n",
    "\n",
    "def stack_batch_split(batch):\n",
    "    return np.reshape(batch, [batch.shape[0]*batch.shape[1], batch.shape[2], batch.shape[3], batch.shape[4]])\n",
    "\n",
    "\n",
    "def unflatten_batch(batch, n_channels=1):\n",
    "    print(np.sqrt(batch.shape[2]/n_channels))\n",
    "    side_square = int(np.sqrt(batch.shape[2]/n_channels))\n",
    "    return np.reshape(batch, [batch.shape[0], batch.shape[1], side_square, side_square, n_channels])\n",
    "\n",
    "def join_batch_split(batch):\n",
    "    batch_size = batch.shape[0]\n",
    "    n_squares = batch.shape[1]\n",
    "    side_quare = batch.shape[2]\n",
    "    n_channels = batch.shape[4]\n",
    "    n_squares_side = int(np.sqrt(n_squares))\n",
    "    batch = np.transpose(batch, [0, 1, 3, 2, 4])\n",
    "    batch = np.reshape(batch, [batch_size, n_squares_side, side_square*n_squares_side, side_square, n_channels])\n",
    "    batch = np.transpose(batch, [0,1, 3,2,4])\n",
    "    batch = np.reshape(batch, [batch_size, 1, side_square*n_squares_side, side_square*n_squares_side, n_channels])\n",
    "    batch = np.reshape(batch, [batch_size, side_square*n_squares_side, side_square*n_squares_side, n_channels])\n",
    "    return batch\n",
    "\n",
    "def resized_dims(n_squares_side):\n",
    "    if(n_squares_side==2):\n",
    "        side = 28\n",
    "        side_square = 14\n",
    "    if(n_squares_side==3):\n",
    "        side = 27\n",
    "        side_square = 9\n",
    "    if(n_squares_side==4):\n",
    "        side = 28\n",
    "        side_square = 7\n",
    "    if(n_squares_side==5):\n",
    "        side = 30\n",
    "        side_square = 6\n",
    "    if(n_squares_side==6):\n",
    "        side = 30\n",
    "        side_square = 5\n",
    "    if(n_squares_side==7):\n",
    "        side = 28\n",
    "        side_square = 4\n",
    "    if(n_squares_side==8):\n",
    "        side = 32\n",
    "        side_square = 4\n",
    "    if(n_squares_side==9):\n",
    "        side = 27\n",
    "        side_square = 3\n",
    "    if(n_squares_side==16):\n",
    "        side = 160\n",
    "        side_square = 10\n",
    "    if(n_squares_side==14):\n",
    "        side = 196\n",
    "        side_square = 14\n",
    "    if(n_squares_side==18):\n",
    "        side = 8*18\n",
    "        side_square = 8\n",
    "    if(n_squares_side==20):\n",
    "        side = 7*20\n",
    "        side_square = 7\n",
    "    if(n_squares_side==25):\n",
    "        side = 25*6\n",
    "        side_square = 6\n",
    "    if(n_squares_side==30):\n",
    "        side = 30*5\n",
    "        side_square = 5\n",
    "    return side, side_square\n",
    "\n",
    "def resize_batch_color(batch, side_new, n_channels):\n",
    "    batch_new = np.zeros((batch.shape[0], side_new, side_new, n_channels))\n",
    "    side = int(np.sqrt(batch.shape[1]))\n",
    "    for i in range(batch.shape[0]):\n",
    "        for c in range(n_channels):\n",
    "            a = imresize(batch[i,:,:,c], [side_new, side_new])\n",
    "            \n",
    "            a = a/255.0\n",
    "            batch_new[i,:,:,c] =a\n",
    "    return batch_new\n",
    "\n",
    "\n",
    "def soft_to_hard(soft_perm):\n",
    "    \n",
    "    a,b = linear_sum_assignment(-soft_perm)\n",
    "    ma = np.zeros((np.shape(soft_perm)))\n",
    "    for i in range(soft_perm.shape[0]):\n",
    "        ma[i, b[i]] = 1\n",
    "    return ma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model params\n",
    "batch_size = 2\n",
    "samples_per_num = 1\n",
    "n_iter_sinkhorn = 2000\n",
    "\n",
    "temp = 150.0\n",
    "\n",
    "#mnist data\n",
    "n_squares_side = 30\n",
    "n_channels = 3\n",
    "\n",
    "n_squares = n_squares_side **2\n",
    "n_gromov = 5\n",
    "side, side_square = resized_dims(n_squares_side)\n",
    "n_dim = int(side_square*side_square*n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now we define the main TF variables\n",
    "\n",
    "def solve(real_split, scrambled_split,stack_scrambled_images_split,stack_real_images_split):\n",
    "    \n",
    "    print(scrambled_split.shape)\n",
    "    log_alpha = np.reshape(stack_scrambled_images_split, [batch_size, n_squares, n_dim])\n",
    "    log_alpha2 = np.reshape(stack_real_images_split, [batch_size, n_squares, n_dim])\n",
    "\n",
    "\n",
    "\n",
    "    sq = np.sum(log_alpha **2, axis=2, keepdims=True)\n",
    "    A = np.tile(sq, [1, 1, n_squares])\n",
    "    B = np.tile(np.transpose(sq, [0,2 ,1]), [1, n_squares, 1])\n",
    "    C = -2*np.matmul(log_alpha, np.transpose(log_alpha, [0, 2, 1]))\n",
    "    s1 = A+B +C\n",
    "    sq2 = np.sum(log_alpha2 **2, axis=2, keepdims=True)\n",
    "    A2 = np.tile(sq2, [1, 1, n_squares])\n",
    "    B2 = np.tile(np.transpose(sq2, [0,2 ,1]), [1, n_squares, 1])\n",
    "    C2 = np.matmul(-2*log_alpha2, np.transpose(log_alpha2, [0, 2, 1]))\n",
    "    s2 = A2+B2 +C2\n",
    "    f1 = np.tile(np.sum(s1**2, axis=2, keepdims=True),[1, 1, n_squares]) \n",
    "    f2 = np.transpose(np.tile(np.sum(s2**2, axis=2, keepdims=True),[1, 1, n_squares]), [0, 2 ,1]) \n",
    "    P = np.tile(np.eye(n_squares)[np.newaxis,:,:], [batch_size, 1, 1])\n",
    "    \n",
    "    invP_all = []\n",
    "    for l in range(n_gromov):\n",
    "        \n",
    "            \n",
    "        ma = -1*(f1+f2 - 2*np.matmul(s1, np.matmul(P, s2)))\n",
    "        for k in range(batch_size):\n",
    "            print([l,k])\n",
    "            P[k,:,:] = sinkhorn(ma[k,:,:]/temp, n_iters = n_iter_sinkhorn)\n",
    "       \n",
    "        invP_all.append(np.transpose(P, [0, 2,1]))\n",
    "    \n",
    "    \n",
    "    inv_P = np.transpose(P, [0, 2,1])\n",
    "   \n",
    "    scrambled_split_tiled = np.reshape(scrambled_split, [batch_size, n_squares, side_square ** 2* n_channels])\n",
    "\n",
    "    ordered_inf = np.matmul(inv_P, scrambled_split_tiled)\n",
    "\n",
    "    return ordered_inf,inv_P, invP_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gomena/.local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0425 16:33:57.803925 140525452928832 deprecation.py:323] From /home/gomena/.local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Lets train the model\n",
    "\n",
    "train_ds = tfds.as_numpy(tfds.load(name='celeb_a',batch_size=batch_size)['train'])\n",
    "test_ds = tfds.as_numpy(tfds.load(name='celeb_a',batch_size=batch_size)['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(iter, type='other',test_ds=None):\n",
    "    if(test_ds is None):\n",
    "        test_ds = tfds.as_numpy(tfds.load(name='celeb_a',batch_size=batch_size)['test'])\n",
    "    batch_size_test=batch_size\n",
    "    np_x = next(test_ds)['image']\n",
    "    if(type == 'other'):\n",
    "        np_x2 = next(test_ds)['image']\n",
    "    else:\n",
    "        np_x2 = np_x\n",
    "    np_x = resize_batch_color(np_x, side, n_channels)\n",
    "\n",
    "    np_x2 = resize_batch_color(np_x2, side, n_channels)\n",
    "    \n",
    "    real_images_split = batch_split(np_x, n_squares_side, n_channels)\n",
    "    real_images_split2 = batch_split(np_x2, n_squares_side, n_channels)\n",
    "\n",
    "    scrambled_images_split = np.zeros(real_images_split.shape)\n",
    "\n",
    "    for i in range(batch_size_test):\n",
    "        if(type=='self'):\n",
    "            perm = np.random.permutation(n_squares)\n",
    "        else:\n",
    "            perm = np.arange(n_squares)\n",
    "        scrambled_images_split[i,:, :, :] = real_images_split[i, perm, :, :]\n",
    "    stacked_scrambled_images_split = stack_batch_split(scrambled_images_split)\n",
    "    stacked_real_images_split = stack_batch_split(real_images_split2)\n",
    "    \n",
    "\n",
    "    unscrambled_images, inv_soft_perms_np,invP_all=solve(real_images_split2,scrambled_images_split,stacked_scrambled_images_split,stacked_real_images_split)\n",
    "    from time import time\n",
    "    a=time()\n",
    "    batch_size_display = 2\n",
    "    unscrambled_images = unscrambled_images[:batch_size_display,:,:]\n",
    "    unflatten_inf = unflatten_batch(unscrambled_images, n_channels)\n",
    "    \n",
    "   \n",
    "    joined_inf = join_batch_split(unflatten_inf)\n",
    "    joined_scrambled = join_batch_split(scrambled_images_split)\n",
    "    joined_real = join_batch_split(real_images_split2)\n",
    "  \n",
    "    #Compare reconstructions with real data\n",
    "\n",
    "    fig, ax = plt.subplots(batch_size_display,3+n_gromov,figsize=(30,10))\n",
    "\n",
    "    for i in range(batch_size_display):\n",
    "\n",
    "        ax[i,0].imshow(joined_real[i,:,:,:],cmap='Greys')\n",
    "        ax[i,0].get_xaxis().set_visible(False)\n",
    "        ax[i,0].get_yaxis().set_visible(False)\n",
    "\n",
    "        ax[i,1].imshow(joined_scrambled[i,:,:,:],cmap='Greys')\n",
    "        ax[i,1].get_xaxis().set_visible(False)\n",
    "        ax[i,1].get_yaxis().set_visible(False)\n",
    "\n",
    "        ax[i,2].imshow(joined_inf[i,:,:,:],cmap='Greys')\n",
    "        ax[i,2].get_xaxis().set_visible(False)\n",
    "        ax[i,2].get_yaxis().set_visible(False)\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "#         if(i==0):\n",
    "#             ax[i,0].set_title('Real',fontsize =25)\n",
    "#             ax[i,1].set_title('Real Scrambled',fontsize =25)\n",
    "#             ax[i,2].set_title('Soft Reconstructed',fontsize =25)\n",
    "#             ax[i,3].set_title('Hard Reconstructed',fontsize =25)\n",
    "    for k in range(n_gromov):\n",
    "        inv_hard_perms= np.zeros((batch_size_display, n_squares, n_squares))\n",
    "        for i in range(batch_size_display):\n",
    "            a=time()\n",
    "            inv_hard_perms[i,:,:] = soft_to_hard(invP_all[k][i,:,:])\n",
    "            print(time()-a)\n",
    "            #inv_hard_perms[i,:,:] = soft_inv2[i,0,:,:].T\n",
    "\n",
    "        hard_inf = np.matmul(inv_hard_perms, np.reshape(scrambled_images_split[:batch_size_display,:,:,:], [batch_size_display,n_squares_side **2 ,-1]))\n",
    "        unflatten_hard_inf =np.reshape(hard_inf, unflatten_inf.shape)\n",
    "        joined_hard_inf =join_batch_split(unflatten_hard_inf)\n",
    "        for i in range(batch_size_display):\n",
    "            ax[i,3+k].imshow(joined_hard_inf[i,:,:,:],cmap='Greys')\n",
    "            ax[i,3+k].get_xaxis().set_visible(False)\n",
    "            ax[i,3+k].get_yaxis().set_visible(False)\n",
    "    plt.savefig('nonn' + type + str(iter) +'.png')\n",
    "    return inv_soft_perms_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gomena/.local/lib/python2.7/site-packages/ipykernel_launcher.py:97: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 900, 5, 5, 3)\n",
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "rrr=plot_results(0,'other')\n",
    "rr=plot_results(0,'self')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot_results(15,'other',test_ds)\n",
    "#plt.imshow(rr[2,:,:])\n",
    "plt.plot(np.nansum(rrr[1,:,:],axis=0))\n",
    "np.nansum(rr[0,:,:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_x  = next(train_ds)['image']\n",
    "\n",
    "np_x = resize_batch_color(np_x, side, n_channels)\n",
    "\n",
    "np_x2 = next(train_ds)['image']\n",
    "np_x2 = np_x\n",
    "np_x2 = resize_batch_color(np_x2, side, n_channels)\n",
    "\n",
    "real_images_split = batch_split(np_x, n_squares_side, n_channels)\n",
    "real_images_split2 = batch_split(np_x2, n_squares_side, n_channels)\n",
    "\n",
    "scrambled_images_split = np.zeros(real_images_split.shape)\n",
    "\n",
    "for j in range(batch_size):\n",
    "    perm = np.random.permutation(n_squares)\n",
    "    scrambled_images_split[j,:, :, :] = real_images_split2[j, perm, :, :]\n",
    "stacked_scrambled_images_split = stack_batch_split(scrambled_images_split)\n",
    "stacked_real_images_split = stack_batch_split(real_images_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stacked_real_images_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
